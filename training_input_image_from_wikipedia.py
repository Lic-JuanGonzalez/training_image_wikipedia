# -*- coding: utf-8 -*-
"""training input image from wikipedia.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sqwQwzxjga1OnssjPm6xyqBvcXyqlWI6
"""

import requests
from PIL import Image
import numpy as np
import tensorflow as tf
from sklearn import datasets
from sklearn.model_selection import train_test_split

response = requests.get("https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Mona_Lisa,_by_Leonardo_da_Vinci,_from_C2RMF_retouched.jpg/1200px-Mona_Lisa,_by_Leonardo_da_Vinci,_from_C2RMF_retouched.jpg")
image_data = response.content

# Guardar la imagen descargada
with open("mona_lisa.jpg", "wb") as f:
  f.write(image_data)

# Cargar la imagen guardada
image = Image.open("mona_lisa.jpg")

image_array = np.array(image)

# 2D array
image_2d = image_array.reshape((image_array.shape[0] * image_array.shape[1], 3))

# Split training and testing sets
X_train, X_test, y_train, y_test = train_test_split(image_2d, np.zeros(image_2d.shape[0]), test_size=0.2, random_state=42)

# Modelo
model = tf.keras.Sequential([
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(64, activation='relu'),
  tf.keras.layers.Dense(3, activation='softmax')
])

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit(X_train, y_train, epochs=2)

model.evaluate(X_test, y_test)